{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do web scrapping of afisha.ru: we need to collect info about restaurants in Moscow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firstly, we'll collect the restaurants links by going through all the pages with Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(7636) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(7677) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     next_button \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPagination_pagination-next__rtqsZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#try to click next page button\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     next_button\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.afisha.ru\"\n",
    "url = f\"{base_url}/msk/restaurants/restaurant_list/\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(7)\n",
    "\n",
    "all_links = set()  #We need to use set to avoid repeat links\n",
    "\n",
    "while True:\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        if \"href\" in a.attrs and a[\"href\"].startswith(\"/msk/restaurant\"): #Search only links starts with /msk/restaurant\n",
    "            all_links.add(a[\"href\"])\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, 'Pagination_pagination-next__rtqsZ')#try to click next page button\n",
    "        next_button.click()\n",
    "        time.sleep(5)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            close_button = driver.find_element(By.CLASS_NAME, 'popmechanic-close')#unexpectedly a banner pops up on the site, try to close it, as it covers the usual page layout\n",
    "            close_button.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            next_button = driver.find_element(By.CLASS_NAME, 'Pagination_pagination-next__rtqsZ')#try to click next page button again\n",
    "            next_button.click()\n",
    "            time.sleep(5)\n",
    "        except Exception as inner_e:\n",
    "            print(\"There are no more pages:\", inner_e)\n",
    "            break\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We saved 11957 links in 'rest_links.csv'\n"
     ]
    }
   ],
   "source": [
    "#adding base url to links\n",
    "full_links = [base_url + link for link in all_links]\n",
    "all_links_list = list(full_links)\n",
    "\n",
    "df = pd.DataFrame(all_links_list, columns=['Link'])\n",
    "df.to_csv('resto_links.csv', index=False)\n",
    "\n",
    "print(f\"We saved {len(all_links_list)} links in 'rest_links.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"resto_links.csv\")\n",
    "names = [\"for_dima_1\", \"for_dima_2\", \"for_goozel_1\", \"for_goozel_2\", \"for_vera_1\", \"for_vera_2\"]\n",
    "for i, name in enumerate(np.array_split(df, 6)):\n",
    "    name.to_csv(f\"{names[i]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "1. Запускаем ячейку с библиотеками вверху\n",
    "2. Запускаем ячейку снизу\n",
    "3. В следующую ячейку вместо test_links.csv выставляем имя своего файла, например, for_dima_2.csv\n",
    "4. Разделила по 2 части ссылок на каждого, но можно еще дробить, если будет выполняться слишком долго судя по прогрессу в выводе ячейки\n",
    "5. Если парсинг по какой-то причине сбросился, ячейка с кодом остановилась: уже спаршеное можно сохранить в другой файл или поставить вывод результата в файл с другим названием(data1, data2...), \n",
    "посмотреть по прогресс бару, на какой ссылке остановился код, убрать из читаемого файла все ссылки до этой отметки, и запустить парсинг опять\n",
    "6. Если экран заблокируется, парсинг сбросится, можно включить какой-нибудь фильм без звука на полный экран, либо что-то делать в компьютере на время выполнения, либо в настройках запретить блокировку экрана\n",
    "7. Потом все файлы с результатами парсинга можно объединить\n",
    "8. Возможно, мы не успеем спарсить все, но нужно постараться собрать побольше)))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_count(button):\n",
    "    content_div = button.find('div', class_='Button_button__content___D2b_')\n",
    "    if content_div:\n",
    "        counter_span = content_div.find('span', class_='DefaultTag_button__counter__64UpQ')\n",
    "        if counter_span:\n",
    "            return int(counter_span.text)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.87)\nStacktrace:\n0   chromedriver                        0x000000010141bb08 cxxbridge1$str$ptr + 3651580\n1   chromedriver                        0x0000000101414358 cxxbridge1$str$ptr + 3620940\n2   chromedriver                        0x0000000100e7c4b4 cxxbridge1$string$len + 89224\n3   chromedriver                        0x0000000100e57994 core::str::slice_error_fail::ha0e52dbcb60e6bae + 3780\n4   chromedriver                        0x0000000100ee6890 cxxbridge1$string$len + 524388\n5   chromedriver                        0x0000000100ef976c cxxbridge1$string$len + 601920\n6   chromedriver                        0x0000000100eb50b0 cxxbridge1$string$len + 321668\n7   chromedriver                        0x0000000100eb5d00 cxxbridge1$string$len + 324820\n8   chromedriver                        0x00000001013e6e4c cxxbridge1$str$ptr + 3435328\n9   chromedriver                        0x00000001013ea164 cxxbridge1$str$ptr + 3448408\n10  chromedriver                        0x00000001013ce1c0 cxxbridge1$str$ptr + 3333812\n11  chromedriver                        0x00000001013eaa24 cxxbridge1$str$ptr + 3450648\n12  chromedriver                        0x00000001013bf9cc cxxbridge1$str$ptr + 3274432\n13  chromedriver                        0x0000000101405138 cxxbridge1$str$ptr + 3558956\n14  chromedriver                        0x00000001014052b4 cxxbridge1$str$ptr + 3559336\n15  chromedriver                        0x0000000101413fcc cxxbridge1$str$ptr + 3620032\n16  libsystem_pthread.dylib             0x000000018e749f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000018e744d34 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(link)\n\u001b[1;32m     14\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_source\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m,class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle_header__SIloF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#bill = soup.find('div',class_ = \"RestaurantExtraInfo_table__l34_J\").find('div',class_ = \"RestaurantExtraInfo_table-cell__fk6SJ\").find('div',class_ = \"RestaurantExtraInfo_cell-data__3Xfkk\").text\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_PAGE_SOURCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.87)\nStacktrace:\n0   chromedriver                        0x000000010141bb08 cxxbridge1$str$ptr + 3651580\n1   chromedriver                        0x0000000101414358 cxxbridge1$str$ptr + 3620940\n2   chromedriver                        0x0000000100e7c4b4 cxxbridge1$string$len + 89224\n3   chromedriver                        0x0000000100e57994 core::str::slice_error_fail::ha0e52dbcb60e6bae + 3780\n4   chromedriver                        0x0000000100ee6890 cxxbridge1$string$len + 524388\n5   chromedriver                        0x0000000100ef976c cxxbridge1$string$len + 601920\n6   chromedriver                        0x0000000100eb50b0 cxxbridge1$string$len + 321668\n7   chromedriver                        0x0000000100eb5d00 cxxbridge1$string$len + 324820\n8   chromedriver                        0x00000001013e6e4c cxxbridge1$str$ptr + 3435328\n9   chromedriver                        0x00000001013ea164 cxxbridge1$str$ptr + 3448408\n10  chromedriver                        0x00000001013ce1c0 cxxbridge1$str$ptr + 3333812\n11  chromedriver                        0x00000001013eaa24 cxxbridge1$str$ptr + 3450648\n12  chromedriver                        0x00000001013bf9cc cxxbridge1$str$ptr + 3274432\n13  chromedriver                        0x0000000101405138 cxxbridge1$str$ptr + 3558956\n14  chromedriver                        0x00000001014052b4 cxxbridge1$str$ptr + 3559336\n15  chromedriver                        0x0000000101413fcc cxxbridge1$str$ptr + 3620032\n16  libsystem_pthread.dylib             0x000000018e749f94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000018e744d34 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "with open('data.csv', 'w', encoding='utf-8-sig', newline='') as d:\n",
    "    file_writer =  csv.writer(d, delimiter = \";\")\n",
    "    file_writer.writerow([\"title\", \"rating\", \"address\", \"metro\", \"avg_check\", \"breakfast\", \"business_lunch\", \"deleviry\", \"parking\", \"catering\", \"banquets\", \"telephone\", \"site\", \"restaurant_type\", \"open_hours\", \"positive_reviews\", \"negative_reviews\"]) \n",
    "\n",
    "with open('test_links.csv','r') as f:\n",
    "    all_links = f.readlines()\n",
    "\n",
    "total_links = len(all_links)\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i, link in enumerate(tqdm(all_links, desc=\"Links processing\", unit=\"link\", dynamic_ncols=True)):\n",
    "    try:\n",
    "\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            \n",
    "        name = soup.find('span',class_ = \"Title_header__SIloF\").text\n",
    "        rank = soup.find('div',class_ = \"RestaurantCover_rating-wrapper__CTNts\")\n",
    "        if rank!=None:\n",
    "            estimate = rank.text\n",
    "        else:\n",
    "            estimate = 0\n",
    "        adress = soup.find('div', class_=\"SectionTitle_wrapper__nAAJ0 RestaurantExtraInfo_address__aJsK2\").text\n",
    "        metro = soup.find_all('ul', class_=\"RestaurantExtraInfo_metro-list__KTBX3\")\n",
    "        metro_=[]\n",
    "        for i in metro:\n",
    "            for j in i.find_all('span', class_=\"Text_text__e9ILn\"):\n",
    "                metro_ += [j.text]\n",
    "        s = ''       \n",
    "        all = soup.find_all('div',class_ = \"RestaurantExtraInfo_table__l34_J\")\n",
    "        for i in all:\n",
    "            for j in i.find_all('span', class_=\"Text_text__e9ILn\"):\n",
    "                s += j.text + ','\n",
    "            tot =s.split(',')[1:len(s):2]   \n",
    "        bill = tot[0] \n",
    "        brekfast = tot[1]\n",
    "        business =  tot[2]\n",
    "        delivery = tot[3]\n",
    "        parking = tot[4]\n",
    "        keit = tot[5]\n",
    "        feast = tot[6] \n",
    "        phone_num = tot[7]\n",
    "        site_ = tot[8] \n",
    "        type_all = []\n",
    "        type_ = soup.find_all('div',class_ = \"RestaurantExtraInfo_tag__BqQ7e\")\n",
    "        for i in type_:\n",
    "            for j in i.find_all('div', class_=\"Button_button__content___D2b_\"):\n",
    "                type_all +=[j.text] \n",
    "        work = soup.find_all('div',class_ = \"RestaurantCover_content-wrapper__72Dox\")\n",
    "        for i in work:\n",
    "            for j in i.find_all('span', class_=\"Text_text__e9ILn\"):\n",
    "                e = j          \n",
    "        open_ = e.text.strip('Открыто c')    \n",
    "\n",
    "        filters_div = soup.find('div', class_='FiltersReview_filters__7E8qs')\n",
    "        positive_reviews = 0\n",
    "        negative_reviews = 0\n",
    "\n",
    "        if filters_div:\n",
    "            buttons = filters_div.find_all('button', class_='Button_button__j_Rc9')\n",
    "            for button in buttons:\n",
    "                content_div = button.find('div', class_='Button_button__content___D2b_')\n",
    "                if content_div:\n",
    "                    text = content_div.text\n",
    "                    if 'Положительные' in text:\n",
    "                        positive_reviews = get_reviews_count(button)\n",
    "                    elif 'Отрицательные' in text:\n",
    "                        negative_reviews = get_reviews_count(button)\n",
    "\n",
    "                    \n",
    "        with open('data.csv', 'a', encoding='utf-8-sig', newline='') as d:\n",
    "            file_writer =  csv.writer(d, delimiter = \";\")\n",
    "            file_writer.writerow([name, estimate, adress, metro_, bill, brekfast ,business ,delivery ,parking ,keit ,feast ,phone_num , site_, type_all, open_, positive_reviews, negative_reviews])\n",
    "\n",
    "    except TypeError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Link processing error {link}: {e}\")\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
